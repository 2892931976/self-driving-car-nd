{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "* constant tensor `tf.constant()`\n",
    "    * Value of tensor never changes, hence *constant*.\n",
    "    * `tf.constant(1234)` is a 0-dimensional int32 tensor\n",
    "    * `tf.constant([1,2,3,4])` is a 4-dimensional int32 tensor\n",
    "\n",
    "Sample code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called tensor\n",
    "hello_constant = tf.constant('Hello World!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "* An environment for running a graph. In charge of allocating the operations to GPU(s) and/or CPU(s).\n",
    "\n",
    "Continuing our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "* `tf.placeholder()`: returns a tensor that gets it’s value from data passed to the `tf.session.run()` function, allowing you to set the input right before the session runs.\n",
    "* `feed_dict`: Use the feed_dict parameter in tf.session.run() to set the placeholder tensor. \n",
    "\n",
    "Example: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.string)\n",
    "b = tf.placeholder(tf.int32)\n",
    "c = tf.placeholder(tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(a, feed_dict={a: 'hi', b: 23, c: 32.0})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also works if you feed it only `{a: 'hi'}`, i.e. the relevant placeholder value(s).\n",
    "\n",
    "\n",
    "## Maths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 6, 10, 2]\n"
     ]
    }
   ],
   "source": [
    "# Add, subtract, multiply and divide operations\n",
    "add = tf.add(5, 2) # 7\n",
    "sub = tf.sub(10, 4) # 6\n",
    "mul = tf.mul(2, 5)  # 10\n",
    "div = tf.div(10, 5) # 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = [sess.run(add), sess.run(sub), sess.run(mul), \n",
    "              sess.run(div)]\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[TF Math documentation](https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops.html)\n",
    "\n",
    "## Variables\n",
    "\n",
    "* `tf.Variable()` function creates a tensor with an initial value that can be modified later, much like a normal Python variable. This tensor stores it’s state in the session, so you must use the `tf.initialize_all_variables()` function to initialize the state of the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialisation\n",
    "\n",
    "def variables():\n",
    "    output = None\n",
    "    \n",
    "    x = tf.Variable([1, 2, 3, 4])\n",
    "    \n",
    "    # Initialise all variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        output = sess.run(x)\n",
    "    \n",
    "    return output\n",
    "\n",
    "variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80277288, -1.83862185],\n",
       "       [ 1.24173021,  3.4572463 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "def logits():\n",
    "    output = None\n",
    "    x_data = [[1.0, 2.0], [2.5, 6.3]]\n",
    "    test_weights = [[-0.3545495, -0.17928936], [-0.63093454, 0.74906588]]\n",
    "    class_size = 2\n",
    "    \n",
    "    \n",
    "    x = tf.placeholder(tf.float32)\n",
    "    weights = tf.Variable(test_weights)\n",
    "    biases = tf.Variable(tf.zeros([class_size]))\n",
    "    \n",
    "    # ToDo: Implement wx + b in TensorFlow\n",
    "    logits = tf.matmul(weights, x)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        output = sess.run(logits, feed_dict={x: x_data})\n",
    "        \n",
    "    return output\n",
    "\n",
    "logits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Turns logits into probabilities that sum to 1.\n",
    "* `tf.nn.softmax()`.\n",
    "\n",
    "Example of how it works:\n",
    "\n",
    "```\n",
    "# logits is a one-dimensional array with 3 elements\n",
    "logits = [1.0, 2.0, 3.0]\n",
    "# softmax will return a one-dimensional array with 3 elements\n",
    "print softmax(logits)\n",
    "\n",
    "[ 0.09003057  0.24472847  0.66524096]\n",
    "\n",
    "# logits is a two-dimensional array\n",
    "logits = np.array([\n",
    "    [1, 2, 3, 6],\n",
    "    [2, 4, 5, 6],\n",
    "    [3, 8, 7, 6]])\n",
    "# softmax will return a two-dimensional array with the same shape\n",
    "print softmax(logits)\n",
    "\n",
    "\n",
    "[\n",
    "    [ 0.09003057  0.00242826  0.01587624  0.33333333]\n",
    "    [ 0.24472847  0.01794253  0.11731043  0.33333333]\n",
    "    [ 0.66524096  0.97962921  0.86681333  0.33333333]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax function in ram Python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # TODO: Compute and return softmax(x)\n",
    "    # S(y_i) = (e**(y_i) / sum_over_j(e**y_j))\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's some elegant Numpy code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax with TF\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    logit_data = [2.0, 1.0, 0.1]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # ToDo: Calculate the softmax of the logits\n",
    "    softmax = tf.nn.softmax(logits)    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # ToDo: Feed in the logits data\n",
    "        output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling and Softmax\n",
    "* When you divide all the logits by e.g. 10, the probabilities get closer to the uniform distribution.\n",
    "* When you multiply all the logits by e.g. 10, the probabilities get closer to 0.0 or 1.0.\n",
    "\n",
    "## One-Hot Encodings\n",
    "* Vectors with one 1.0 and 0.0 everywhere else.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
