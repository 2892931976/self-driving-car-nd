{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lane Lines\n",
    "\n",
    "Features: Colour, Shape, Orientation, Position in the image.\n",
    "1. Colour\n",
    "    - e.g. RGB: [255,255,255] (Three colour channels, 0 is darkest and 255 is brightest.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "# Variables\n",
    "image_name='test.jpg'\n",
    "\n",
    "# Read in the image and print out some stats\n",
    "image = mpimg.imread(image_name)\n",
    "print('This image is: ', type(image), ' with dimensions: ', image.shape)\n",
    "\n",
    "# Grab the x and y size and amke a copy of the image\n",
    "# Think of it as a matrix so rows are y and cols are x\n",
    "ysize = image.shape[0]\n",
    "xsize = image.shape[1]\n",
    "color_select = np.copy(image)\n",
    "\n",
    "# Define our colour selection criteria.\n",
    "# I.e. the minimum values for RGB that we will allow in our selection.\n",
    "red_threshold = 240\n",
    "green_threshold = 240\n",
    "blue_threshold = 240\n",
    "rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "\n",
    "# Define criteria to select any pixels below the threshold\n",
    "# Using a 'bitwise OR'\n",
    "# Red component of pixel is less than red threshold or G...or B...\n",
    "thresholds = (image[:,:,0] < rgb_threshold[0]) \\\n",
    "            | (image[:,:,1] < rgb_threshold[1]) \\\n",
    "            | (image[:,:,2 < rgb_threshold[2]])\n",
    "\n",
    "# Set any pixels below the threshold to zero (black) in copy of \n",
    "# image `color_select'\n",
    "color_select[thresholds] = [0,0,0]\n",
    "\n",
    "# Resulting image: Pixels above the threshold (brighter) have been retained,\n",
    "# pixels below the threshold blacked out.\n",
    "plt.imshow(color_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'In this case, I'll assume that the front facing camera that took the image is mounted in a fixed position on the car, such that the lane lines will always appear in the same general region of the image. Next, I'll take advantage of this by adding a criterion to only consider pixels for color selection in the region where we expect to find the lane lines.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coding up a region of interest mask\n",
    "\n",
    "# Define a triangular region of interest\n",
    "# [y_from_top_down, x_from_left_to_right]\n",
    "# Dimensions of this image: 540 (rows), 960 (cols), 3\n",
    "left_bottom = [120, 540]\n",
    "right_bottom = [800, 540]\n",
    "apex = [480, 300]\n",
    "\n",
    "# Fit lines (y=Ax+B) to identify the 3-sided region of interest.\n",
    "# np.polyfit() returns the coefficients [A, B] of the fit.\n",
    "# Left line, i.e. line between `left_bottom` and `apex`\n",
    "# np.polyfit(x, y, deg_of_fitting_polynomial)\n",
    "fit_left = np.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "fit_right = np.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "\n",
    "# Find the region inside the lines\n",
    "# np.meshgrid returns coordinate matrices from coordinate vectors.\n",
    "# returns two arrays of arrays\n",
    "XX, YY = np.meshgrid(np.arange(0, xsize), np.arange(0, ysize))\n",
    "region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                    (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                    (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "\n",
    "# Find where image is both coloured right and in the region\n",
    "region_select[~region_thresholds] = [255,0,0]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(region_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_image = np.copy(image)\n",
    "\n",
    "# Find where the image is both coloured right and in the region\n",
    "# ~ colour_thresholds: selects pixels BRIGHTER than the colour thershold\n",
    "# region_thresholds: selects pixel IN the region\n",
    "# Colour these pixels red.\n",
    "line_image[~color_thresholds & region_thresholds] = [255,0,0]\n",
    "\n",
    "plt.imshow(line_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX, YY = np.meshgrid(np.arange(0,100), np.arange(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        ..., \n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99]]), array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 2,  2,  2, ...,  2,  2,  2],\n",
       "        ..., \n",
       "        [97, 97, 97, ..., 97, 97, 97],\n",
       "        [98, 98, 98, ..., 98, 98, 98],\n",
       "        [99, 99, 99, ..., 99, 99, 99]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.meshgrid(np.arange(0,100), np.arange(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       ..., \n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  1,  1,  1],\n",
       "       [ 2,  2,  2, ...,  2,  2,  2],\n",
       "       ..., \n",
       "       [97, 97, 97, ..., 97, 97, 97],\n",
       "       [98, 98, 98, ..., 98, 98, 98],\n",
       "       [99, 99, 99, ..., 99, 99, 99]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer vision: using algorithms to let the computer see the world like we do. Depth, colour, shapes, meaning.\n",
    "\n",
    "### Canny Edge Detection\n",
    "Identifying the boundaries of an object in an image\n",
    "- Convert to grayscale\n",
    "- Compute gradient (brighter pixel -> stronger gradient)\n",
    "- Find edges by identifying pixels wwith strongest gradient.\n",
    "\n",
    "#### Canny algorithm\n",
    "Computing gradient gives us thick edges. -> Canny algorithm thins edges to individual pixels that have strongest gradients.\n",
    "\n",
    "```\n",
    "edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "```\n",
    "\n",
    "Summary\n",
    "- Apply Canny to image `gray` and return binary (B&W) image `edges`.\n",
    "- Edges will be white and the rest of the image will be black.\n",
    "\n",
    "Steps:\n",
    "1. Alg first detects strong gradient pixels above the `high_threshold` and rejects pixels below the `low_threshold` value. \n",
    "2. Next, pixels with values between the `low_threshold` and `high_threshold` will be included as long as they are connected to strong edges.\n",
    "\n",
    "#### Reasonable range for parameters\n",
    "- E.g. In an 8-bit image, each pixel has 256 possible values (0-255). So the derivatives will be on the scale of tens to hundreds. \n",
    "    - Range for threshold parameters: tens to hundreds\n",
    "- Ratio `low_threshold:high_threshold`: 1:2 or 1:3 (John Canny)\n",
    "\n",
    "#### Gaussian smoothing to suppress noise and spurious gradients\n",
    "- Larger `kernel_size` -> smoothing over a larger area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Read in image\n",
    "image = mpimg.imread('exit_ramp.jpg')\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Show image\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "\n",
    "# Define a kernel size for Gaussian smoothing / blurring\n",
    "# Kernel size must be an odd number.\n",
    "kernel_size = 3\n",
    "# Run Gaussian smoothing\n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "# Define parameters for Canny edge detector\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "# Run Canny edge detector on the image\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "plt.imshow(edges, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough transform\n",
    "- Motivation: Previously have image of points. Need to find lines.\n",
    "- Hough Transform: Conversion from image space to Hough space (space in parameter m, b of line). \n",
    "    - Each line in image space is then a point in Hough space.\n",
    "    - Each point in image space is a line in Hough space. -.-\n",
    "    - Two points in image space correspond to two intersecting lines in Hough Space.\n",
    "    - The intersection point of two lines in Hough space corresponds to a line in image space that passes through \n",
    "- Look for intersecting lines in Hough space to find lines in image space.\n",
    "- Do this by dividing Hough Space into grid and define intersecting lines as all lines passing through a grid cell.\n",
    "- But cannot represent vertical lines (infinite slope) in m,b representation. So represent in **polar coordinates** (theta, rho) instead.\n",
    "    - Points in image space become sine curves in Hough Space. Okaay?\n",
    "\n",
    "Use OpenCV function **HoughesLineP** to specify parameters to say what kind of lines we want to detect (long, short, bendy, dashed lines)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
