{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lane Lines\n",
    "\n",
    "Features: Colour, Shape, Orientation, Position in the image.\n",
    "1. Colour\n",
    "    - e.g. RGB: [255,255,255] (Three colour channels, 0 is darkest and 255 is brightest.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "# Variables\n",
    "image_name='test.jpg'\n",
    "\n",
    "# Read in the image and print out some stats\n",
    "image = mpimg.imread(image_name)\n",
    "print('This image is: ', type(image), ' with dimensions: ', image.shape)\n",
    "\n",
    "# Grab the x and y size and amke a copy of the image\n",
    "# Think of it as a matrix so rows are y and cols are x\n",
    "ysize = image.shape[0]\n",
    "xsize = image.shape[1]\n",
    "color_select = np.copy(image)\n",
    "\n",
    "# Define our colour selection criteria.\n",
    "# I.e. the minimum values for RGB that we will allow in our selection.\n",
    "red_threshold = 240\n",
    "green_threshold = 240\n",
    "blue_threshold = 240\n",
    "rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "\n",
    "# Define criteria to select any pixels below the threshold\n",
    "# Using a 'bitwise OR'\n",
    "# Red component of pixel is less than red threshold or G...or B...\n",
    "thresholds = (image[:,:,0] < rgb_threshold[0]) \\\n",
    "            | (image[:,:,1] < rgb_threshold[1]) \\\n",
    "            | (image[:,:,2 < rgb_threshold[2]])\n",
    "\n",
    "# Set any pixels below the threshold to zero (black) in copy of \n",
    "# image `color_select'\n",
    "color_select[thresholds] = [0,0,0]\n",
    "\n",
    "# Resulting image: Pixels above the threshold (brighter) have been retained,\n",
    "# pixels below the threshold blacked out.\n",
    "plt.imshow(color_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'In this case, I'll assume that the front facing camera that took the image is mounted in a fixed position on the car, such that the lane lines will always appear in the same general region of the image. Next, I'll take advantage of this by adding a criterion to only consider pixels for color selection in the region where we expect to find the lane lines.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coding up a region of interest mask\n",
    "\n",
    "# Define a triangular region of interest\n",
    "# [y_from_top_down, x_from_left_to_right]\n",
    "# Dimensions of this image: 540 (rows), 960 (cols), 3\n",
    "left_bottom = [120, 540]\n",
    "right_bottom = [800, 540]\n",
    "apex = [480, 300]\n",
    "\n",
    "# Fit lines (y=Ax+B) to identify the 3-sided region of interest.\n",
    "# np.polyfit() returns the coefficients [A, B] of the fit.\n",
    "# Left line, i.e. line between `left_bottom` and `apex`\n",
    "# np.polyfit(x, y, deg_of_fitting_polynomial)\n",
    "fit_left = np.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "fit_right = np.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "\n",
    "# Find the region inside the lines\n",
    "# np.meshgrid returns coordinate matrices from coordinate vectors.\n",
    "# returns two arrays of arrays\n",
    "XX, YY = np.meshgrid(np.arange(0, xsize), np.arange(0, ysize))\n",
    "region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                    (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                    (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "\n",
    "# Find where image is both coloured right and in the region\n",
    "region_select[~region_thresholds] = [255,0,0]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(region_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_image = np.copy(image)\n",
    "\n",
    "# Find where the image is both coloured right and in the region\n",
    "# ~ colour_thresholds: selects pixels BRIGHTER than the colour thershold\n",
    "# region_thresholds: selects pixel IN the region\n",
    "# Colour these pixels red.\n",
    "line_image[~color_thresholds & region_thresholds] = [255,0,0]\n",
    "\n",
    "plt.imshow(line_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX, YY = np.meshgrid(np.arange(0,100), np.arange(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        ..., \n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99],\n",
       "        [ 0,  1,  2, ..., 97, 98, 99]]), array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 2,  2,  2, ...,  2,  2,  2],\n",
       "        ..., \n",
       "        [97, 97, 97, ..., 97, 97, 97],\n",
       "        [98, 98, 98, ..., 98, 98, 98],\n",
       "        [99, 99, 99, ..., 99, 99, 99]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.meshgrid(np.arange(0,100), np.arange(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       ..., \n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99],\n",
       "       [ 0,  1,  2, ..., 97, 98, 99]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  1,  1,  1],\n",
       "       [ 2,  2,  2, ...,  2,  2,  2],\n",
       "       ..., \n",
       "       [97, 97, 97, ..., 97, 97, 97],\n",
       "       [98, 98, 98, ..., 98, 98, 98],\n",
       "       [99, 99, 99, ..., 99, 99, 99]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer vision: using algorithms to let the computer see the world like we do. Depth, colour, shapes, meaning.\n",
    "\n",
    "### Canny Edge Detection\n",
    "Identifying the boundaries of an object in an image\n",
    "- Convert to grayscale\n",
    "- Compute gradient (brighter pixel -> stronger gradient)\n",
    "- Find edges by identifying pixels wwith strongest gradient.\n",
    "\n",
    "#### Canny algorithm\n",
    "Computing gradient gives us thick edges. -> Canny algorithm thins edges to individual pixels that have strongest gradients.\n",
    "\n",
    "```\n",
    "edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "```\n",
    "\n",
    "Summary\n",
    "- Apply Canny to image `gray` and return binary (B&W) image `edges`.\n",
    "- Edges will be white and the rest of the image will be black.\n",
    "\n",
    "Steps:\n",
    "1. Alg first detects strong gradient pixels above the `high_threshold` and rejects pixels below the `low_threshold` value. \n",
    "2. Next, pixels with values between the `low_threshold` and `high_threshold` will be included as long as they are connected to strong edges.\n",
    "\n",
    "#### Reasonable range for parameters\n",
    "- E.g. In an 8-bit image, each pixel has 256 possible values (0-255). So the derivatives will be on the scale of tens to hundreds. \n",
    "    - Range for threshold parameters: tens to hundreds\n",
    "- Ratio `low_threshold:high_threshold`: 1:2 or 1:3 (John Canny)\n",
    "\n",
    "#### Gaussian smoothing to suppress noise and spurious gradients\n",
    "- Larger `kernel_size` -> smoothing over a larger area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Read in image\n",
    "image = mpimg.imread('exit_ramp.jpg')\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Show image\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "\n",
    "# Define a kernel size for Gaussian smoothing / blurring\n",
    "# Kernel size must be an odd number.\n",
    "kernel_size = 3\n",
    "# Run Gaussian smoothing\n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "# Define parameters for Canny edge detector\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "# Run Canny edge detector on the image\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "plt.imshow(edges, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough transform\n",
    "- Motivation: Previously have image of points. Need to find lines.\n",
    "- Hough Transform: Conversion from image space to Hough space (space in parameter m, b of line). \n",
    "    - Each line in image space is then a point in Hough space.\n",
    "    - Each point in image space is a line in Hough space. -.-\n",
    "    - Two points in image space correspond to two intersecting lines in Hough Space.\n",
    "    - The intersection point of two lines in Hough space corresponds to a line in image space that passes through \n",
    "- Look for intersecting lines in Hough space to find lines in image space.\n",
    "- Do this by dividing Hough Space into grid and define intersecting lines as all lines passing through a grid cell.\n",
    "- But cannot represent vertical lines (infinite slope) in m,b representation. So represent in **polar coordinates** (theta, rho) instead.\n",
    "    - Points in image space become sine curves in Hough Space. Okaay?\n",
    "\n",
    "Use OpenCV function **HoughesLineP** to specify parameters to say what kind of lines we want to detect (long, short, bendy, dashed lines).\n",
    "\n",
    "```\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                       min_len_length, max_line_gap)\n",
    "```\n",
    "- `edges`: image, output from `Canny`.\n",
    "- output `lines` is an array containing the endpoints (x1, x2, y1, y2) of all line segments detected by the transform operation.\n",
    "- Other parameters define what kind of line segments we're looking for:\n",
    "    - rho, theta: distance and angular resulotion of our grid in Hough space \n",
    "        - rho in pixels, min 1\n",
    "        - theta: usually 1 degree (pi/180 rad) + \n",
    "    - threshold: minimum number of votes (intersections in a given grid cell{ a candidate line needs to have to make it into the output.\n",
    "    - `np.array([])`: a placeholder, don't have to change this (what is this for? putting the output in?)\n",
    "    - `min_line_length`: minimum length of a line (in pixels) you will accept in the output\n",
    "    - `max_line_gap`: maximum distance in pixels between segments that you will allow to be connected into a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Read in and grayscale the image\n",
    "image = mpimg.imread('exit_ramp.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define a kernel size and apply Gaussian smoothing\n",
    "kernel_size = 5\n",
    "blur_gray = cv2.GaussiaBlur(gray, (kernel_size, kernel_size), 0)\n",
    "\n",
    "# Define our parameters for Canny and apply\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "# Define the Hough transform parameters\n",
    "rho = 1\n",
    "theta = np.pi/180\n",
    "threshold = 1\n",
    "min_line_length = 10\n",
    "max_line_gap = 1\n",
    "# Make a blank image the same size as our image to draw on\n",
    "line_image = np.copy(image)*0\n",
    "\n",
    "# Find lines in the image\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                       min_len_length, max_line_gap)\n",
    "\n",
    "# Iterate over the output 'lines' and draw lines on the blank image\n",
    "# Here, the line segments are drawn in red.\n",
    "for line in lines:\n",
    "    for x1, y1, x2, y2 in line:\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (255,0,0), 10)\n",
    "\n",
    "# Create a 'color' binary image to combine with line image\n",
    "color_edges = np.dstack((edges, edges, edges))\n",
    "\n",
    "# Draw the lines on the edge image\n",
    "combo = cv2.AddWeighted(color_edges, 0.8, line_image, 1, 0)\n",
    "plt.imshow(combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hough Transform Quiz Code\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Read in and grayscale the image\n",
    "# Note: in the previous example we were reading a .jpg \n",
    "# Here we read a .png and convert to 0,255 bytescale\n",
    "image = (mpimg.imread('exit_ramp.png')*255).astype('uint8')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define a kernel size and apply Gaussian smoothing\n",
    "kernel_size = 5\n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "\n",
    "# Define our parameters for Canny and apply\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "# Next we'll create a masked edges image using cv2.fillPoly()\n",
    "mask = np.zeros_like(edges)   \n",
    "ignore_mask_color = 255   \n",
    "\n",
    "# This time we are defining a four sided polygon to mask\n",
    "imshape = image.shape\n",
    "# TODO: Define parameters for Four-sided polygon\n",
    "vertices = np.array([[(80,540),(460, 280), (490, 280), (900,540)]], dtype=np.int32)\n",
    "cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "masked_edges = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "# Define the Hough transform parameters\n",
    "# Make a blank the same size as our image to draw on\n",
    "rho = 1 # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "threshold = 1     # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 30 #minimum number of pixels making up a line\n",
    "max_line_gap = 15    # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)\n",
    "\n",
    "# Iterate over the output \"lines\" and draw lines on a blank image\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "\n",
    "# Create a \"color\" binary image to combine with line image\n",
    "color_edges = np.dstack((edges, edges, edges)) \n",
    "\n",
    "# Draw the lines on the edge image\n",
    "lines_edges = cv2.addWeighted(color_edges, 0.8, line_image, 1, 0) \n",
    "plt.imshow(lines_edges)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "For region selection, I defined vertices = np.array([[(0,imshape[0]),(450, 290), (490, 290), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "\n",
    "I chose parameters for my Hough space grid to be a rho of 2 pixels and theta of 1 degree (pi/180 radians). I chose a threshold of 15, meaning at least 15 points in image space need to be associated with each line segment. I imposed a min_line_length of 40 pixels, and max_line_gap of 20 pixels.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(np.dstack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
