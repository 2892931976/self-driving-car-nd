{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, SpatialDropout2D, ELU\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Cropping2D\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  9384\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "reduced = False\n",
    "\n",
    "if reduced == True:\n",
    "    csv_filepath = 'data-udacity/driving_log_reduced.csv'\n",
    "else:\n",
    "    csv_filepath = 'data-udacity/driving_log.csv'\n",
    "samples = []\n",
    "with open(csv_filepath) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "        \n",
    "def add_to_samples(csv_filepath, samples):\n",
    "    with open(csv_filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            samples.append(line)\n",
    "    return samples\n",
    "\n",
    "samples = add_to_samples('data-recovery-annie/driving_log.csv', samples)\n",
    "\n",
    "samples = samples[1:]\n",
    "print(\"Samples: \", len(samples))    \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = './data-udacity/'+batch_sample[0]\n",
    "                # name = './data-udacity/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = mpimg.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            \n",
    "            # print(\"X_train: \", X_train)\n",
    "            # print(\"y_train: \", y_train)\n",
    "            yield shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_comma(image):\n",
    "    import tensorflow as tf  # This import is required here otherwise the model cannot be loaded in drive.py\n",
    "    return tf.image.resize_images(image, 40, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "cropping2d_7 (Cropping2D)        (None, 65, 320, 3)    0           cropping2d_input_7[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)               (None, 40, 160, 3)    0           cropping2d_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)               (None, 40, 160, 3)    0           lambda_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 10, 40, 16)    3088        lambda_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_36 (ELU)                     (None, 10, 40, 16)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 5, 20, 32)     12832       elu_36[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "elu_37 (ELU)                     (None, 5, 20, 32)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 3, 10, 64)     51264       elu_37[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 1920)          0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "elu_38 (ELU)                     (None, 1920)          0           flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 512)           983552      elu_38[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "elu_39 (ELU)                     (None, 512)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             513         elu_39[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 1051249\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Comma.ai model\n",
    "# https://github.com/commaai/research/blob/master/train_steering_model.py\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Crop 50 pixels from the top of the image and 20 from the bottom\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0)),\n",
    "                     dim_ordering='tf', # default\n",
    "                     input_shape=(160, 320, 3)))\n",
    "\n",
    "# Resize the data\n",
    "model.add(Lambda(resize_comma))\n",
    "\n",
    "model.add(Lambda(lambda x: (x/255.0) - 0.5))\n",
    "\n",
    "model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "\n",
    "model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(.2))\n",
    "model.add(ELU())\n",
    "\n",
    "model.add(Dense(512))\n",
    "# model.add(Dropout(.5))\n",
    "model.add(ELU())\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=adam, loss=\"mse\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing reference: [Geoff Breemer](https://carnd-forums.udacity.com/questions/36045049/answers/36047341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.5765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessica/anaconda/lib/python3.5/site-packages/keras/engine/training.py:1470: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: saving model to ./tmp/comma-v3g.00-0.01.hdf5\n",
      "8462/8445 [==============================] - 44s - loss: 0.0122 - acc: 0.5760 - val_loss: 0.0127 - val_acc: 0.5527\n",
      "Epoch 2/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.5766Epoch 00001: saving model to ./tmp/comma-v3g.01-0.01.hdf5\n",
      "8462/8445 [==============================] - 42s - loss: 0.0111 - acc: 0.5768 - val_loss: 0.0129 - val_acc: 0.5469\n",
      "Epoch 3/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.5773Epoch 00002: saving model to ./tmp/comma-v3g.02-0.01.hdf5\n",
      "8462/8445 [==============================] - 38s - loss: 0.0107 - acc: 0.5773 - val_loss: 0.0125 - val_acc: 0.5448\n",
      "Epoch 4/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.5754Epoch 00003: saving model to ./tmp/comma-v3g.03-0.01.hdf5\n",
      "8462/8445 [==============================] - 36s - loss: 0.0100 - acc: 0.5750 - val_loss: 0.0123 - val_acc: 0.5475\n",
      "Epoch 5/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.5779Epoch 00004: saving model to ./tmp/comma-v3g.04-0.01.hdf5\n",
      "8462/8445 [==============================] - 36s - loss: 0.0097 - acc: 0.5781 - val_loss: 0.0118 - val_acc: 0.5432\n",
      "Epoch 6/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.5745Epoch 00005: saving model to ./tmp/comma-v3g.05-0.01.hdf5\n",
      "8462/8445 [==============================] - 35s - loss: 0.0095 - acc: 0.5747 - val_loss: 0.0123 - val_acc: 0.5327\n",
      "Epoch 7/20\n",
      "8416/8445 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.5745Epoch 00006: saving model to ./tmp/comma-v3g.06-0.01.hdf5\n",
      "8448/8445 [==============================] - 34s - loss: 0.0094 - acc: 0.5747 - val_loss: 0.0114 - val_acc: 0.5454\n",
      "Epoch 8/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.5719Epoch 00007: saving model to ./tmp/comma-v3g.07-0.01.hdf5\n",
      "8462/8445 [==============================] - 34s - loss: 0.0090 - acc: 0.5727 - val_loss: 0.0122 - val_acc: 0.5559\n",
      "Epoch 9/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.5776Epoch 00008: saving model to ./tmp/comma-v3g.08-0.01.hdf5\n",
      "8462/8445 [==============================] - 33s - loss: 0.0087 - acc: 0.5769 - val_loss: 0.0125 - val_acc: 0.5570\n",
      "Epoch 10/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.5765Epoch 00009: saving model to ./tmp/comma-v3g.09-0.01.hdf5\n",
      "8462/8445 [==============================] - 32s - loss: 0.0086 - acc: 0.5762 - val_loss: 0.0124 - val_acc: 0.5633\n",
      "Epoch 11/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.5772Epoch 00010: saving model to ./tmp/comma-v3g.10-0.01.hdf5\n",
      "8462/8445 [==============================] - 32s - loss: 0.0085 - acc: 0.5775 - val_loss: 0.0123 - val_acc: 0.5454\n",
      "Epoch 12/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.5762Epoch 00011: saving model to ./tmp/comma-v3g.11-0.01.hdf5\n",
      "8462/8445 [==============================] - 32s - loss: 0.0083 - acc: 0.5756 - val_loss: 0.0125 - val_acc: 0.5506\n",
      "Epoch 13/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.5775Epoch 00012: saving model to ./tmp/comma-v3g.12-0.01.hdf5\n",
      "8462/8445 [==============================] - 32s - loss: 0.0081 - acc: 0.5775 - val_loss: 0.0129 - val_acc: 0.5485\n",
      "Epoch 14/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.5746Epoch 00013: saving model to ./tmp/comma-v3g.13-0.01.hdf5\n",
      "8462/8445 [==============================] - 34s - loss: 0.0081 - acc: 0.5748 - val_loss: 0.0136 - val_acc: 0.5479\n",
      "Epoch 15/20\n",
      "8416/8445 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.5749Epoch 00014: saving model to ./tmp/comma-v3g.14-0.01.hdf5\n",
      "8448/8445 [==============================] - 33s - loss: 0.0080 - acc: 0.5747 - val_loss: 0.0137 - val_acc: 0.5443\n",
      "Epoch 16/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.5716Epoch 00015: saving model to ./tmp/comma-v3g.15-0.01.hdf5\n",
      "8462/8445 [==============================] - 33s - loss: 0.0078 - acc: 0.5714 - val_loss: 0.0127 - val_acc: 0.5475\n",
      "Epoch 17/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.5800Epoch 00016: saving model to ./tmp/comma-v3g.16-0.01.hdf5\n",
      "8462/8445 [==============================] - 33s - loss: 0.0076 - acc: 0.5795 - val_loss: 0.0137 - val_acc: 0.5380\n",
      "Epoch 18/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.5751Epoch 00017: saving model to ./tmp/comma-v3g.17-0.01.hdf5\n",
      "8462/8445 [==============================] - 35s - loss: 0.0076 - acc: 0.5753 - val_loss: 0.0128 - val_acc: 0.5401\n",
      "Epoch 19/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.5756Epoch 00018: saving model to ./tmp/comma-v3g.18-0.01.hdf5\n",
      "8462/8445 [==============================] - 35s - loss: 0.0076 - acc: 0.5763 - val_loss: 0.0126 - val_acc: 0.5496\n",
      "Epoch 20/20\n",
      "8430/8445 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.5771Epoch 00019: saving model to ./tmp/comma-v3g.19-0.01.hdf5\n",
      "8462/8445 [==============================] - 35s - loss: 0.0074 - acc: 0.5771 - val_loss: 0.0133 - val_acc: 0.5570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1296bb9e8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 32\n",
    "nb_epoch = 20\n",
    " \n",
    "checkpointer = ModelCheckpoint(filepath=\"./tmp/s2.{epoch:02d}-{val_loss:.2f}.hdf5\", verbose=1, save_best_only=False)\n",
    "    \n",
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=len(train_samples), \n",
    "                    validation_data=validation_generator,\n",
    "                    nb_val_samples=len(validation_samples), nb_epoch=nb_epoch,\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model-s2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
